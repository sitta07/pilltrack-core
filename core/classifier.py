import torch
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image
import cv2
import numpy as np
import json
import os

# Import Structure ‡πÄ‡∏î‡∏¥‡∏°
from core.architecture import PillModel 

class SmartClassifier:
    def __init__(self, model_dir="models/"):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model_dir = model_dir
        
        # ==========================================
        # ‚öôÔ∏è CONFIG: ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
        # ==========================================
        # ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ best_model.pth ‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà (‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡πÅ‡∏Å‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)
        self.pill_config = {
            "weights": "best_model_pills.pth",       
            "mapping": "class_mapping_pills.json", # üî• ‡πÅ‡∏¢‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡∏Ç‡∏≠
            "img_size": 224,
            "model_name": "convnext_small"
        }
        
        self.box_config = {
            "weights": "best_model_box.pth",       # ‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô box_model.pth
            "mapping": "class_mapping_box.json",   # üî• ‡πÅ‡∏¢‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡∏Ç‡∏≠
            "img_size": 224,                   # ‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô 512
            "model_name": "convnext_small"
        }
        # ==========================================

        print(f"üöÄ Initializing SmartClassifier on {self.device}...")

        # 1. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• PILL ‡πÄ‡∏Ç‡πâ‡∏≤ Memory
        self.model_pill, self.classes_pill, self.tfm_pill = self._load_single_model(self.pill_config)
        
        # 2. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• BOX ‡πÄ‡∏Ç‡πâ‡∏≤ Memory
        self.model_box, self.classes_box, self.tfm_box = self._load_single_model(self.box_config)

        # 3. ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ Pointer (‡∏ä‡∏µ‡πâ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô)
        self.active_model = self.model_pill
        self.active_classes = self.classes_pill
        self.active_tfm = self.tfm_pill
        self.current_mode = "PILL"

        print("‚úÖ Dual Models Loaded & Ready!")

    def _load_single_model(self, config):
        """Helper Function: ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• 1 ‡∏ï‡∏±‡∏ß"""
        path_weight = os.path.join(self.model_dir, config["weights"])
        path_map = os.path.join(self.model_dir, config["mapping"])

        # A. Load Mapping
        idx_to_class = {}
        num_classes = 5 # Default
        if os.path.exists(path_map):
            try:
                with open(path_map, 'r') as f:
                    raw = json.load(f)
                    idx_to_class = {int(k): v for k, v in raw.items()}
                    num_classes = len(idx_to_class)
                print(f"   üìÑ Loaded mapping: {config['mapping']} ({num_classes} classes)")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Error loading {config['mapping']}: {e}")
        else:
            print(f"   ‚ö†Ô∏è Warning: {config['mapping']} not found. Using dummy classes.")

        # B. Setup Model Architecture
        model = PillModel(
            num_classes=num_classes,
            model_name=config["model_name"],
            embed_dim=512,
            dropout=0.0
        ).to(self.device)

        # C. Load Weights
        if os.path.exists(path_weight):
            checkpoint = torch.load(path_weight, map_location=self.device)
            model.load_state_dict(checkpoint)
            model.eval() # üî• Important
            print(f"   üíæ Loaded weights: {config['weights']}")
        else:
            print(f"   ‚ùå Error: Weight file {config['weights']} not found!")

        # D. Setup Transform
        tfm = transforms.Compose([
            transforms.Resize((config["img_size"], config["img_size"])),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                 std=[0.229, 0.224, 0.225])
        ])

        return model, idx_to_class, tfm

    def switch_mode(self, mode):
        """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏•‡∏±‡∏ö‡∏™‡∏°‡∏≠‡∏á (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏à‡∏≤‡∏Å UI)"""
        if mode == "BOX":
            self.active_model = self.model_box
            self.active_classes = self.classes_box
            self.active_tfm = self.tfm_box
            self.current_mode = "BOX"
        else:
            self.active_model = self.model_pill
            self.active_classes = self.classes_pill
            self.active_tfm = self.tfm_pill
            self.current_mode = "PILL"
            
        print(f"üîÑ Switched Classifier to: {self.current_mode}")

    def predict(self, cv2_image):
        """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Active Model ‡∏ì ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"""
        if cv2_image is None or cv2_image.size == 0:
            return "Error", 0.0

        # Preprocess
        rgb = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(rgb)
        tensor_img = self.active_tfm(pil_img).unsqueeze(0).to(self.device)

        with torch.no_grad():
            # Extract Feature
            features = self.active_model(tensor_img)
            
            # ArcFace Similarity Check
            norm_feat = F.normalize(features)
            norm_weight = F.normalize(self.active_model.head.weight)
            logits = F.linear(norm_feat, norm_weight)
            probs = F.softmax(logits * 30.0, dim=1)
            
            conf, pred_idx = torch.max(probs, 1)
            
            idx = pred_idx.item()
            name = self.active_classes.get(idx, f"Unknown-{idx}")
            
            return name, conf.item()